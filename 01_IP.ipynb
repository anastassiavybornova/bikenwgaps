{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18034f14",
   "metadata": {},
   "source": [
    "# DOC\n",
    "## LAST UPDATE: 2022-02-17\n",
    "## IPDC PROCEDURE\n",
    "## STEPS 1(I) AND 2 (P): IDENTIFY AND PRIORITIZE GAPS\n",
    "\n",
    "input: pickle files from step 0 - simplified network in igraph and nx, ebc values & conversion tables\n",
    "* \"./data/pickle/H.gpickle\"\n",
    "* \"./data/pickle/h.pickle\"\n",
    "* \"./data/pickle/eids_conv.pickle\"\n",
    "* \"./data/pickle/nids_conv.pickle\"\n",
    "* \"./data/pickle/ebc.pickle\" \n",
    "\n",
    "output: \n",
    "* \"./data/pickle/mygaps.pickle\" - dataframe of prioritized gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0a6b2",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3ca776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%run -i packages.py\n",
    "\n",
    "### CUSTOM FUNCTIONS\n",
    "\n",
    "# computes pathlength by nx - handling error message if nodes are not connected/not part of the network\n",
    "def pathlength_if_connected(my_nw, my_o, my_d):\n",
    "    try:\n",
    "        return(nx.dijkstra_path_length(my_nw, my_o, my_d, weight = \"length\"))\n",
    "    except:\n",
    "        return(math.inf)\n",
    "    \n",
    "# get list of edge coordinates for plotting from list of nx edge ids:\n",
    "def get_path_coords(my_path, my_coorddict):\n",
    "    pathcoords = []\n",
    "    for edge_id in my_path:\n",
    "        edge_coords = [(c[1], c[0]) for c in my_coorddict[tuple(sorted(edge_id))].coords]\n",
    "        pathcoords.append(edge_coords)\n",
    "    return(pathcoords) \n",
    "\n",
    "# IMPORT OBJECTS FROM PREVIOUS STEPS\n",
    "\n",
    "H = nx.read_gpickle(\"./data/pickle/H.gpickle\")\n",
    "B = nx.read_gpickle(\"./data/pickle/B.gpickle\")\n",
    "h = ig.Graph.Read_Pickle(\"./data/pickle/h.pickle\")\n",
    "\n",
    "nids_conv = pd.read_pickle(\"./data/pickle/nids_conv.pickle\")\n",
    "eids_conv = pd.read_pickle(\"./data/pickle/eids_conv.pickle\")\n",
    "\n",
    "ebc = pd.read_pickle(\"./data/pickle/ebc.pickle\")\n",
    "\n",
    "# GENERATE NX ATTRIBUTE DICTIONARIES\n",
    "ced = nx.get_edge_attributes(H, \"coord\") # coordinates of edges dictionary ced\n",
    "ted = nx.get_edge_attributes(H, \"category_edge\") # type of edges dictionary ted\n",
    "tnd = nx.get_node_attributes(H, \"category_node\") # type of nodes dictionary tnd\n",
    "cnd = nx.get_node_attributes(H, \"coord\") # coordinates of nodes dictionary cnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efeb8e",
   "metadata": {},
   "source": [
    "# IDENTIFY ALL GAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc7fc5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9924  gaps found\n"
     ]
    }
   ],
   "source": [
    "### GET plist = LIST OF SHORTEST PATHS FOR ALL POSSIBLE CONTACT-TO-CONTACT NODE COMBINATIONS\n",
    "\n",
    "plist = []\n",
    "os.mkdir(\"./data/chunks\")\n",
    "\n",
    "# ALL CONTACT NODES FROM THE NETWORK\n",
    "nodestack = [node.index for node in h.vs() if h.vs[node.index][\"category_node\"]==\"multi\"]\n",
    "\n",
    "count = 0\n",
    "\n",
    "while nodestack:\n",
    "    \n",
    "    node = nodestack.pop()\n",
    "    \n",
    "    # ADDING SHORTEST PATHS FROM CURRENT NODE TO ALL OTHER NODES REMAINING IN THE STACK \n",
    "    plist = plist + h.get_shortest_paths(node, to=nodestack, weights=\"length\", mode=\"out\", output = \"epath\")\n",
    "    \n",
    "    # CHUNKWISE SAVING OF RESULTS (TO BE READ IN LATER)\n",
    "    if len(plist) >= 10**6:\n",
    "        with open(\"./data/chunks/c\" + str(count) + \".pickle\", 'wb') as handle:\n",
    "            pickle.dump(plist, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del(plist)\n",
    "        count += 1\n",
    "        plist = []\n",
    "        \n",
    "        \n",
    "# SAVING LAST CHUNK (WITH LEN < 10**6)\n",
    "with open(\"./data/chunks/c\" + str(count) + \".pickle\", 'wb') as handle:\n",
    "    pickle.dump(plist, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del(plist)\n",
    "\n",
    "### LOOP THROUGH ALL SHORTEST PATHS; KEEP ONLY THE PATHS THAT CONSIST ONLY OF CAR LINKS\n",
    "\n",
    "# cs: set of car edges\n",
    "cs = set()\n",
    "for edge in eids_conv[\"ig\"]:\n",
    "    if h.es[edge][\"category_edge\"] == \"car\":\n",
    "        cs.add(edge)\n",
    "\n",
    "mygaps = []\n",
    "\n",
    "# CHUNKWISE:\n",
    "\n",
    "mychunks = [\"./data/chunks/\" + filename for filename in os.listdir(\"./data/chunks/\")]\n",
    "\n",
    "for chunk in mychunks:\n",
    "    \n",
    "    with open(chunk, 'rb') as f:\n",
    "        pathlist = pickle.load(f)\n",
    "\n",
    "    # adding the item to the gaplist only if it consists of only-car-edges\n",
    "    gaplist = [item for item in pathlist if set(item).issubset(cs)]\n",
    "\n",
    "    mygaps = mygaps + gaplist\n",
    "    \n",
    "    del(gaplist, pathlist)\n",
    "    \n",
    "print(len(mygaps), \" gaps found\")\n",
    "\n",
    "# remove chunks (not needed anymore)\n",
    "for chunk in mychunks:\n",
    "    os.remove(chunk)\n",
    "os.rmdir(\"./data/chunks\")\n",
    "\n",
    "# CONVERT GAPS LIST TO DF AND ADD LENGTH, ORIGIN, DESTINATION\n",
    "\n",
    "# to df\n",
    "mygaps = pd.DataFrame({\"path\": mygaps})\n",
    "\n",
    "# add length\n",
    "mygaps[\"length\"] = mygaps.apply(lambda x: np.sum([h.es[e][\"length\"] for e in x.path]), axis = 1)\n",
    "\n",
    "# add path in nx edge id\n",
    "mygaps[\"path_nx\"] = mygaps.apply(lambda x: \n",
    "                                 [tuple(sorted(literal_eval(h.es[edge][\"edge_id\"]))) for edge in x.path], \n",
    "                                 axis = 1)\n",
    "\n",
    "# add origin and destination nodes\n",
    "# (separate procedure for gaps with edgenumber (enr) == 1 vs. gaps with enr > 1)\n",
    "mygaps[\"enr\"] = mygaps.apply(lambda x: len(x.path), axis = 1)\n",
    "mygaps[\"o_nx\"] = None\n",
    "mygaps[\"d_nx\"] = None\n",
    "mygaps.loc[mygaps[\"enr\"]==1, \"o_nx\"] = mygaps[mygaps[\"enr\"] == 1].apply(lambda x: x.path_nx[0][0], axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]==1, \"d_nx\"] = mygaps[mygaps[\"enr\"] == 1].apply(lambda x: x.path_nx[0][1], axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]!=1, \"o_nx\"] = mygaps[mygaps[\"enr\"]!=1].apply(lambda x: set(x.path_nx[0]).difference(x.path_nx[1]).pop(), axis = 1)\n",
    "mygaps.loc[mygaps[\"enr\"]!=1, \"d_nx\"] = mygaps[mygaps[\"enr\"]!=1].apply(lambda x: set(x.path_nx[-1]).difference(x.path_nx[-2]).pop(), axis = 1)\n",
    "mygaps.drop(columns = \"enr\", inplace = True)\n",
    "\n",
    "# add coordinates for  plotting\n",
    "mygaps[\"gapcoord\"] = mygaps.apply(lambda x: get_path_coords(x.path_nx, ced), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4ef8d",
   "metadata": {},
   "source": [
    "# DISCARD \"PARALLEL PATHS\" (GAPS CONNECTED ON BICYCLE NETWORK WITH A DETOUR FACTOR BELOW D_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8af1d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_min = 1.5 # set minimum detour factor for path to count as gap\n",
    "\n",
    "# compute detour factor on bike network\n",
    "mygaps[\"length_b\"] = mygaps.apply(lambda x: pathlength_if_connected(B, x.o_nx, x.d_nx), axis = 1)\n",
    "mygaps[\"detour\"] = mygaps[\"length_b\"]/mygaps[\"length\"]\n",
    "mygaps = mygaps[mygaps[\"detour\"]>=D_min].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb616d",
   "metadata": {},
   "source": [
    "# PRIORITIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a967588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute benefit metric B_star(g)\n",
    "mygaps[\"B_star\"] = mygaps.apply(lambda x: \n",
    "                                        np.sum([ebc.loc[ebc[\"edge_ig\"]==i, \"ebc_lambda\"] * \\\n",
    "                                                h.es[i][\"length\"] \\\n",
    "                                                for i in x.path]), \n",
    "                                        axis = 1)\n",
    "mygaps[\"B\"] = mygaps[\"B_star\"] / mygaps[\"length\"] # B(g) normed to length\n",
    "\n",
    "# sort gaps by descending benefit metric\n",
    "mygaps = mygaps.sort_values(by = \"B\", ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcb811",
   "metadata": {},
   "source": [
    "# SAVE RESULTS (INPUT FOR NEXT STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5200a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mygaps.to_pickle(\"./data/pickle/mygaps.pickle\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65611e",
   "metadata": {},
   "source": [
    "### END OF 01_IP NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnwker",
   "language": "python",
   "name": "bnwker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
